ngramFiles <- c("uniSample.RData","biSample.RData","triSample.RData")
file.exists(ngramFiles)
!file.exists(ngramFiles)
if (!file.exists(ngramFiles))
Unigram <- NGramTokenizer(docs, Weka_control(min = 1, max = 1,delimiters = "
if (!file.exists(ngramFiles))
Unigram <- NGramTokenizer(docs, Weka_control(min = 1, max = 1,delimiters = " \\r\\n\\t.,;:\"()?!"))
if (!file.exists(ngramFiles[1]) && !file.exists(ngramFiles[2]) && !file.exists(ngramFiles[3]))
Unigram <- NGramTokenizer(docs, Weka_control(min = 1, max = 1,delimiters = " \\r\\n\\t.,;:\"()?!"))
if (!file.exists(ngramFiles[1]) AND !file.exists(ngramFiles[2]) AND !file.exists(ngramFiles[3]))
+       Unigram <- NGramTokenizer(docs, Weka_control(min = 1, max = 1,delimiters = " \\r\\n\\t.,;:\"()?!"))
!file.exists(ngramFiles[2])
if (!file.exists(ngramFiles[1]) & !file.exists(ngramFiles[2]) & !file.exists(ngramFiles[3]))
+       Unigram <- NGramTokenizer(docs, Weka_control(min = 1, max = 1,delimiters = " \\r\\n\\t.,;:\"()?!"))
ngramFiles[1]
!file.exists(ngramFiles[1]) && !file.exists(ngramFiles[2]) && !file.exists(ngramFiles[3])
!file.exists(ngramFiles[1])
!file.exists("data/sample/sampleCorpus.txt")
ngramFiles <- c("./data/uniSample.RData","./data/biSample.RData","./data/triSample.RData")
!file.exists(ngramFiles[1])
!file.exists(ngramFiles[1]) && !file.exists(ngramFiles[2]) && !file.exists(ngramFiles[3])
library("R.utils")
library("RWeka")
library("tm")
library("SnowballC")
library("ggplot2")
enFiles <- list.files(path=dir, recursive=T, pattern=".*en_.*.txt")
l <- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
summaryDF <- data.frame(matrix(unlist(l), nrow=length(l), byrow=T))
colnames(summaryDF) <- c("file", "MBs", "#lines", "longestLine", "#words")
summaryDF
dir <- "data/sample"
enFiles <- list.files(path=dir, recursive=T, pattern=".*en_.*.txt")
l <- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
if (!file.exists("data/sample/sampleCorpus.txt")){
set.seed(234)
blogFile <- file(paste(dir, enFiles, sep="/")[1], open="r")
blog_lines <- readLines(blogFile, skipNul=TRUE)
num_blog_lines <- length(blog_lines)
blog_sample <- blog_lines[sample(1:num_blog_lines, num_blog_lines * 0.05, replace=FALSE)]
con2 <- file("data/sample/sampleCorpus.txt", "w+")
writeLines(blog_sample, con2)
close(con2)
close(blogFile)
newsFile <- file(paste(dir, enFiles, sep="/")[2], open="r")
news_lines <- readLines(newsFile, skipNul = TRUE)
num_news_lines <- length(news_lines)
news_sample <- news_lines[sample(1:num_news_lines, num_news_lines * 0.05, replace=FALSE)]
con2 <- file("data/sample/sampleCorpus.txt", "w+")
writeLines(news_sample, con2)
close(newsFile)
close(con2)
twitterFile <- file(paste(dir, enFiles, sep="/")[3], open="r")
twit_lines <- readLines(twitterFile, skipNul=TRUE)
num_twit_lines <- length(twit_lines)
twit_sample <- twit_lines[sample(1:num_twit_lines, num_twit_lines * 0.05, replace=FALSE)]
con2 <- file("data/sample/sampleCorpus.txt", "w+")
writeLines(twit_sample, con2)
close(con2)
close(twitterFile)
}
if (!file.exists(ngramFiles[1]) && !file.exists(ngramFiles[2]) && !file.exists(ngramFiles[3])){
Unigram <- NGramTokenizer(docs, Weka_control(min = 1, max = 1,delimiters = " \\r\\n\\t.,;:\"()?!"))
Bigram <- NGramTokenizer(docs, Weka_control(min = 2, max = 2,delimiters = " \\r\\n\\t.,;:\"()?!"))
Trigram <- NGramTokenizer(docs, Weka_control(min = 3, max = 3,delimiters = " \\r\\n\\t.,;:\"()?!"))
#sort by word distribution frequency
UnigramTbl <- data.frame(table(Unigram))
UnigramTbl <- UnigramTbl[order(UnigramTbl$Freq,decreasing = TRUE),]
UniSample <- UnigramTbl[1:30,]
colnames(UniSample) <- c("nGram","Frequency")
BigramTbl <- data.frame(table(Bigram))
BigramTbl <- BigramTbl[order(BigramTbl$Freq,decreasing = TRUE),]
BiSample <- BigramTbl[1:30,]
colnames(BiSample) <- c("nGram","Frequency")
TrigramTbl <- data.frame(table(Trigram))
TrigramTbl <- TrigramTbl[order(TrigramTbl$Freq,decreasing = TRUE),]
TriSample <- TrigramTbl[1:30,]
colnames(TriSample) <- c("nGram","Frequency")
#save files
saveRDS(UniSample, file = "./data/uniSample.RData")
saveRDS(BiSample, file = "./data/biSample.RData")
saveRDS(TriSample, file = "./data/triSample.RData")
remove(UnigramTbl,UniSample,BigramTbl,BiSample,TrigramTbl,TriSample)
}
if (!file.exists("data/summaryDF.RData")){
l <- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
}
saveRDS(l, file = "./data/summaryDF.RData")
summaryDF <- data.frame(matrix(unlist(l), nrow=length(l), byrow=T))
colnames(summaryDF) <- c("file", "MBs", "#lines", "longestLine", "#words")
summaryDF
if (!file.exists("data/summaryDF.RData")){
l <- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
saveRDS(l, file = "data/summaryDF.RData")
}
l <- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
saveRDS(l, file = "data/summaryDF.RData")
if (!file.exists("./data/sample/summaryDF.RData")){
l <- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
saveRDS(l, file = "./data/sample/summaryDF.RData")
}
l <- readRDS(file = "./data/sample/summaryDF.RData")
summaryDF <- data.frame(matrix(unlist(l), nrow=length(l), byrow=T))
colnames(summaryDF) <- c("file", "MBs", "#lines", "longestLine", "#words")
summaryDF
remove(l)
dir <- "data/sample"
paste(dir, enFiles, sep="/")
l <- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
saveRDS(l, file = "./data/sample/summaryDF.RData")
readRDS(file = "./data/sample/summaryDF.RData")
remove(l)
l <- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
saveRDS(l, file = "./data/sample/summaryDF.RData")
saveRDS(l, file = "data/sample/summaryDF.RData")
l <- readRDS(file = "./data/sample/summaryDF.RData")
remove(l)
l <- readRDS(file = "./data/sample/summaryDF.RData")
enFiles <- list.files(path=dir, recursive=F, pattern=".*en_.*.txt")
<- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
saveRDS(l, file = "./data/sample/summaryDF.RData")
l <- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
saveRDS(l, file = "./data/sample/summaryDF.RData")
library(shiny)
setwd("./Capstone")
setwd("Capstone")
getwd
getwd()
setwd("C:/Users/schre/DataScience/wd/CAPSTONE")
getwd()
runApp()
runApp()
library(shiny)
runApp()
library(shiny)
runApp()
library(shiny)
runApp()
sampleData <- readRDS(file="./data/quadData.RData")
head(sampleData)
<li>
incremental: true
suppressPackageStartupMessages(c(library(tm),library(shiny),library(dplyr),library(plyr),library(stringr),library(ggplot2)))
ds <- read.csv("./data/SampleData.csv")
dataSubset <- subset(ds, select=c(Gender, CurrentSalary, JobTitle))
setwd("C:/Users/schre/DataScience/wd/EEO/app")
ds <- read.csv("./data/SampleData.csv")
dataSubset <- subset(ds, select=c(Gender, CurrentSalary, JobTitle))
ds <- dataSubset #dataset()
variance <- .10 #input$variance
#get means by Criteria for each Factor
ds.factor.avg <- aggregate(CurrentSalary ~ Gender + JobTitle, data=ds, mean)
ds.factor.avg <- data.frame(ds.factor.avg)
ds.factor.F <- ddply(ds.factor.avg,.(JobTitle),
summarise,meanF = mean(CurrentSalary[Gender == "F"]))
ds.factor.M <- ddply(ds.factor.avg,.(JobTitle),
summarise,meanM = mean(CurrentSalary[Gender == "M"]))
ds.factor <- merge(ds.factor.F, ds.factor.M)
ds.factor.var <- filter(ds.factor, var=(meanF-meanM)/meanM>variance)
ds.factor.var
runApp()
runApp()
runApp()
runApp()
ds.factor.var <- data.frame(rnorm(10))
ds.factor.var
runApp()
paste("hello")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
ds.factor.var
ds.factor.var
ds.factor.var <- filter(ds.factor, var=(meanF-meanM)/meanM>variance)
ds.factor.var
is.na(ds.factor.var)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
dataSubset
subset(ds, select=c(Gender, dataElement, JobTitle))
dataElement <- "CurrentSalary"
subset(ds, select=c(Gender, dataElement, JobTitle))
runApp()
runApp()
runApp()
setwd("C:/Users/schre/DataScience/wd/EEO/app")
runApp()
suppressPackageStartupMessages(c(library(tm),library(shiny),library(dplyr),library(plyr),library(stringr),library(ggplot2)))
runApp()
getwd()
runApp()
