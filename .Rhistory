ngramFiles <- c("uniSample.RData","biSample.RData","triSample.RData")
file.exists(ngramFiles)
!file.exists(ngramFiles)
if (!file.exists(ngramFiles))
Unigram <- NGramTokenizer(docs, Weka_control(min = 1, max = 1,delimiters = "
if (!file.exists(ngramFiles))
Unigram <- NGramTokenizer(docs, Weka_control(min = 1, max = 1,delimiters = " \\r\\n\\t.,;:\"()?!"))
if (!file.exists(ngramFiles[1]) && !file.exists(ngramFiles[2]) && !file.exists(ngramFiles[3]))
Unigram <- NGramTokenizer(docs, Weka_control(min = 1, max = 1,delimiters = " \\r\\n\\t.,;:\"()?!"))
if (!file.exists(ngramFiles[1]) AND !file.exists(ngramFiles[2]) AND !file.exists(ngramFiles[3]))
+       Unigram <- NGramTokenizer(docs, Weka_control(min = 1, max = 1,delimiters = " \\r\\n\\t.,;:\"()?!"))
!file.exists(ngramFiles[2])
if (!file.exists(ngramFiles[1]) & !file.exists(ngramFiles[2]) & !file.exists(ngramFiles[3]))
+       Unigram <- NGramTokenizer(docs, Weka_control(min = 1, max = 1,delimiters = " \\r\\n\\t.,;:\"()?!"))
ngramFiles[1]
!file.exists(ngramFiles[1]) && !file.exists(ngramFiles[2]) && !file.exists(ngramFiles[3])
!file.exists(ngramFiles[1])
!file.exists("data/sample/sampleCorpus.txt")
ngramFiles <- c("./data/uniSample.RData","./data/biSample.RData","./data/triSample.RData")
!file.exists(ngramFiles[1])
!file.exists(ngramFiles[1]) && !file.exists(ngramFiles[2]) && !file.exists(ngramFiles[3])
library("R.utils")
library("RWeka")
library("tm")
library("SnowballC")
library("ggplot2")
enFiles <- list.files(path=dir, recursive=T, pattern=".*en_.*.txt")
l <- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
summaryDF <- data.frame(matrix(unlist(l), nrow=length(l), byrow=T))
colnames(summaryDF) <- c("file", "MBs", "#lines", "longestLine", "#words")
summaryDF
dir <- "data/sample"
enFiles <- list.files(path=dir, recursive=T, pattern=".*en_.*.txt")
l <- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
if (!file.exists("data/sample/sampleCorpus.txt")){
set.seed(234)
blogFile <- file(paste(dir, enFiles, sep="/")[1], open="r")
blog_lines <- readLines(blogFile, skipNul=TRUE)
num_blog_lines <- length(blog_lines)
blog_sample <- blog_lines[sample(1:num_blog_lines, num_blog_lines * 0.05, replace=FALSE)]
con2 <- file("data/sample/sampleCorpus.txt", "w+")
writeLines(blog_sample, con2)
close(con2)
close(blogFile)
newsFile <- file(paste(dir, enFiles, sep="/")[2], open="r")
news_lines <- readLines(newsFile, skipNul = TRUE)
num_news_lines <- length(news_lines)
news_sample <- news_lines[sample(1:num_news_lines, num_news_lines * 0.05, replace=FALSE)]
con2 <- file("data/sample/sampleCorpus.txt", "w+")
writeLines(news_sample, con2)
close(newsFile)
close(con2)
twitterFile <- file(paste(dir, enFiles, sep="/")[3], open="r")
twit_lines <- readLines(twitterFile, skipNul=TRUE)
num_twit_lines <- length(twit_lines)
twit_sample <- twit_lines[sample(1:num_twit_lines, num_twit_lines * 0.05, replace=FALSE)]
con2 <- file("data/sample/sampleCorpus.txt", "w+")
writeLines(twit_sample, con2)
close(con2)
close(twitterFile)
}
if (!file.exists(ngramFiles[1]) && !file.exists(ngramFiles[2]) && !file.exists(ngramFiles[3])){
Unigram <- NGramTokenizer(docs, Weka_control(min = 1, max = 1,delimiters = " \\r\\n\\t.,;:\"()?!"))
Bigram <- NGramTokenizer(docs, Weka_control(min = 2, max = 2,delimiters = " \\r\\n\\t.,;:\"()?!"))
Trigram <- NGramTokenizer(docs, Weka_control(min = 3, max = 3,delimiters = " \\r\\n\\t.,;:\"()?!"))
#sort by word distribution frequency
UnigramTbl <- data.frame(table(Unigram))
UnigramTbl <- UnigramTbl[order(UnigramTbl$Freq,decreasing = TRUE),]
UniSample <- UnigramTbl[1:30,]
colnames(UniSample) <- c("nGram","Frequency")
BigramTbl <- data.frame(table(Bigram))
BigramTbl <- BigramTbl[order(BigramTbl$Freq,decreasing = TRUE),]
BiSample <- BigramTbl[1:30,]
colnames(BiSample) <- c("nGram","Frequency")
TrigramTbl <- data.frame(table(Trigram))
TrigramTbl <- TrigramTbl[order(TrigramTbl$Freq,decreasing = TRUE),]
TriSample <- TrigramTbl[1:30,]
colnames(TriSample) <- c("nGram","Frequency")
#save files
saveRDS(UniSample, file = "./data/uniSample.RData")
saveRDS(BiSample, file = "./data/biSample.RData")
saveRDS(TriSample, file = "./data/triSample.RData")
remove(UnigramTbl,UniSample,BigramTbl,BiSample,TrigramTbl,TriSample)
}
if (!file.exists("data/summaryDF.RData")){
l <- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
}
saveRDS(l, file = "./data/summaryDF.RData")
summaryDF <- data.frame(matrix(unlist(l), nrow=length(l), byrow=T))
colnames(summaryDF) <- c("file", "MBs", "#lines", "longestLine", "#words")
summaryDF
if (!file.exists("data/summaryDF.RData")){
l <- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
saveRDS(l, file = "data/summaryDF.RData")
}
l <- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
saveRDS(l, file = "data/summaryDF.RData")
if (!file.exists("./data/sample/summaryDF.RData")){
l <- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
saveRDS(l, file = "./data/sample/summaryDF.RData")
}
l <- readRDS(file = "./data/sample/summaryDF.RData")
summaryDF <- data.frame(matrix(unlist(l), nrow=length(l), byrow=T))
colnames(summaryDF) <- c("file", "MBs", "#lines", "longestLine", "#words")
summaryDF
remove(l)
dir <- "data/sample"
paste(dir, enFiles, sep="/")
l <- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
saveRDS(l, file = "./data/sample/summaryDF.RData")
readRDS(file = "./data/sample/summaryDF.RData")
remove(l)
l <- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
saveRDS(l, file = "./data/sample/summaryDF.RData")
saveRDS(l, file = "data/sample/summaryDF.RData")
l <- readRDS(file = "./data/sample/summaryDF.RData")
remove(l)
l <- readRDS(file = "./data/sample/summaryDF.RData")
enFiles <- list.files(path=dir, recursive=F, pattern=".*en_.*.txt")
<- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
saveRDS(l, file = "./data/sample/summaryDF.RData")
l <- lapply(paste(dir, enFiles, sep="/"),
function(fileIn) {
con <- file(fileIn, open="r")
fsize <- file.info(fileIn)[1]/1024/1024
testLine <- readLines(con)
nchar <- lapply(testLine, nchar)
maxchars <- which.max(nchar)
words <- sum(sapply(strsplit(testLine, "\\s+"), length))
close(con)
return(c(fileIn, format(round(fsize, 2), nsmall=2), length(testLine), maxchars, words))
})
saveRDS(l, file = "./data/sample/summaryDF.RData")
library(shiny)
setwd("./Capstone")
setwd("Capstone")
getwd
getwd()
setwd("C:/Users/schre/DataScience/wd/CAPSTONE")
getwd()
runApp()
runApp()
library(shiny)
runApp()
library(shiny)
runApp()
library(shiny)
runApp()
sampleData <- readRDS(file="./data/quadData.RData")
head(sampleData)
<li>
incremental: true
library(shiny)
runApp()
setwd("C:/Users/schre/DataScience/wd/EEO/app")
runApp()
getwd()
getwd()
library(shiny)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
dT <- function(input$DataType) {
if(input$DataType=="Salary")
"CurrentSalary"
else if(input$DataType=="TotalCompensation")
"TotalCompensation"
}
dT <-  function(DataType) {
if(DataType=="Salary")
"CurrentSalary"
else if(DataType=="TotalCompensation")
"TotalCompensation"
}
dT("Salary")
ds <- read.csv("./data/SampleData.csv")
dCols <- c(dT("Salary"), dFact("Gender"), dC("Job","YrsOfExperience")) #data type, factor and group by columns
Fact <- function(FactorType) ({
dFact <- NULL
if(FactorType=="Gender"){
dFact <- c("Gender") }
if(FactorType=="Ethnicity") {
dFact <- c("Ethnicity") }
dFact
})
dC <- function(GroupBy) ({
dC <- NULL
if(GroupBy=="Job"){
dC <- c("Job") }
if(GroupBy=="YrsOfExperience") {
dC <- append(dC, "YrsOfExperience") }
dC
})
dCols <- c(dT("Salary"), dFact("Gender"), dC("Job","YrsOfExperience")) #data type, factor and group by columns
dFact <- function(FactorType) ({
dFact <- NULL
if(FactorType=="Gender"){
dFact <- c("Gender") }
if(FactorType=="Ethnicity") {
dFact <- c("Ethnicity") }
dFact
})
dCols <- c(dT("Salary"), dFact("Gender"), dC("Job","YrsOfExperience")) #data type, factor and group by columns
dCols <- c(dT("Salary"), dFact("Gender"), dC(c("Job","YrsOfExperience")))
dT("Salary")
dFact("Gender")
c("Job","YrsOfExperience")
dCols <- c(dT("Salary"), dFact("Gender"), c("Job","YrsOfExperience")) #data type, factor and group by columns
dCols <- c(dT("Salary"), dFact("Gender"), list("Job","YrsOfExperience")) #data type, factor and group by columns
runApp()
runApp()
runApp()
runApp()
runApp()
getwd()
library(shiny)
runApp()
runApp()
library(shiny)
runApp()
runApp()
comp.mean <- { function(df, GroupBy, meanX) {
ddply(df, eval(GroupBy), function(d) c(SalaryMean=mean(d[[meanX]])))
}
}
criteria <- c("Ethnicity","Job")
ds.factor.avg <- comp.mean(ds, criteria, "Salary")
warnings()
criteria <- c("Gender","Job")
ds.factor.avg <- comp.mean(ds, criteria, "Salary")
ds.factor.avg <- comp.mean(ds, criteria, "CurrentSalary")
criteria <- c("Ethnicity","Job")
ds.factor.avg <- comp.mean(ds, criteria, "CurrentSalary")
runApp()
unique(ds.factor.avg[1,])
unique(ds.factor.avg[,1])
colNames(ds.factor.avg)
colnames(ds.factor.avg)
runApp()
runApp()
runApp()
colnames(ds)
colnames(ds)
runApp()
runApp()
"Gender" %in% colnames(ds)
runApp()
library(RMySQL)
install(RMySQL)
install.packages("RMySQL")
runApp()
runApp()
criteria <- c("Job")
ds.factor.avg <- comp.mean(ds, criteria, "CurrentSalary")
ds.factor.avg
ds.factor.avg <- ds
runApp()
ds.factor.avg[,1]
ds.factor.avg[1,]
runApp()
criteria <- c("Job")
ds.factor.avg$GroupMean <- comp.mean(ds.factor.avg, criteria, "CurrentSalary")
ds.factor.GrpAvg$GroupMean <- comp.mean(ds.factor.avg, criteria, "CurrentSalary")
ds.factor.GrpAvg <- comp.mean(ds.factor.avg, criteria, "CurrentSalary")
criteria <- c("Job","Gender")
ds.factor.avg <- comp.mean(ds, criteria, "CurrentSalary")
dsNew <- merge(ds.factor.avg, ds.factor.GrpAvg, by=dGroupBy())
dsNew <- merge(ds.factor.avg, ds.factor.GrpAvg, by="Job")
dsNew <- null
dsNew <- NULL
colnames(ds.factor.GrpAvg) <- c("Gender","Job","meanGrp")
colnames(ds.factor.GrpAvg) <- c("Job","meanGrp")
dsNew <- merge(ds.factor.avg, ds.factor.GrpAvg, by="Job")
runApp()
library(shiny)
runApp()
head(ds.factor.avg)
criteria <- c("Job")
ds.factor.avg <- comp.mean(ds, criteria, "CurrentSalary")
head(ds.factor.avg)
criteria <- c("Job","Gender")
ds.factor.avg <- comp.mean(ds, criteria, "CurrentSalary")
criteria <- c("Job")
ds.factor.GrpAvg <- comp.mean(ds, criteria, "CurrentSalary")
head(ds.factor.avg)
head(ds.factor.GrpAvg)
merge(ds.factor.avg, ds.factor.GrpAvg, by="Job")
head(merge(ds.factor.avg, ds.factor.GrpAvg, by="Job"))
head(ds.factor.GrpAvg)
runApp()
